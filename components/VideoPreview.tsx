
import React, { useState, useEffect, useRef } from 'react';
import { Storyboard, Scene, TelopStyle, YouTubeMetadata, YouTubeConfig } from '../types';
import { FFmpeg } from '@ffmpeg/ffmpeg';
import { fetchFile, toBlobURL } from '@ffmpeg/util';

const BGM_URLS = {
  epic: "https://cdn.pixabay.com/audio/2023/12/04/audio_92425f3898.mp3",
  sad: "https://cdn.pixabay.com/audio/2023/11/24/audio_349d970e7e.mp3",
  peaceful: "https://cdn.pixabay.com/audio/2024/01/16/audio_034a74797a.mp3",
  suspense: "https://cdn.pixabay.com/audio/2024/02/06/audio_40914619d0.mp3"
};

const YOUTUBE_SCOPES = 'https://www.googleapis.com/auth/youtube.upload';

interface VideoPreviewProps {
  storyboard: Storyboard;
  onClose: () => void;
}

const VideoPreview: React.FC<VideoPreviewProps> = ({ storyboard, onClose }) => {
  const [currentSceneIndex, setCurrentSceneIndex] = useState(-2); 
  const [isPlaying, setIsPlaying] = useState(false);
  const [isExporting, setIsExporting] = useState(false);
  const [exportStep, setExportStep] = useState<string>("");
  const [isUploading, setIsUploading] = useState(false);
  const [showUploadForm, setShowUploadForm] = useState(false);
  const [uploadStatus, setUploadStatus] = useState<string | null>(null);
  const [finalVideoBlob, setFinalVideoBlob] = useState<Blob | null>(null);
  const [ffmpegReady, setFfmpegReady] = useState(false);
  const [sceneProgress, setSceneProgress] = useState(0); // For Ken Burns effect

  const ffmpegRef = useRef(new FFmpeg());
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const audioContextRef = useRef<any>(null);
  const bgmBufferRef = useRef<any>(null);
  const audioDestinationRef = useRef<any>(null);
  const mediaRefs = useRef<(HTMLVideoElement | HTMLImageElement | null)[]>([]);
  const animationFrameRef = useRef<number | null>(null);
  const startTimeRef = useRef<number>(0);

  const [ytMeta, setYtMeta] = useState<YouTubeMetadata>({
    title: `${storyboard.subject}の衝撃的な真実`,
    description: `歴史の闇に葬られた${storyboard.subject}の物語。\n\nGenerated by Historian AI\n#歴史 #雑学 #AI動画`,
    tags: `${storyboard.subject}, 歴史, AI, 教育`,
    privacyStatus: 'private'
  });

  useEffect(() => {
    const loadFFmpeg = async () => {
      const baseURL = 'https://unpkg.com/@ffmpeg/core@0.12.6/dist/esm';
      const ffmpeg = ffmpegRef.current;
      try {
        await ffmpeg.load({
          coreURL: await toBlobURL(`${baseURL}/ffmpeg-core.js`, 'text/javascript'),
          wasmURL: await toBlobURL(`${baseURL}/ffmpeg-core.wasm`, 'application/wasm'),
        });
        setFfmpegReady(true);
      } catch (err) {
        console.error("FFmpeg load failed:", err);
        setUploadStatus("映像エンジンの読み込みに失敗しました。再試行してください。");
      }
    };
    loadFFmpeg();
    return () => {
      if (animationFrameRef.current) cancelAnimationFrame(animationFrameRef.current);
    };
  }, []);

  const decodePCM = (base64: string, ctx: any) => {
    const binary = (window as any).atob(base64);
    const bytes = new Uint8Array(binary.length);
    for (let i = 0; i < binary.length; i++) bytes[i] = binary.charCodeAt(i);
    const dataInt16 = new Int16Array(bytes.buffer);
    const buffer = ctx.createBuffer(1, dataInt16.length, 24000);
    const channelData = buffer.getChannelData(0);
    for (let i = 0; i < dataInt16.length; i++) channelData[i] = dataInt16[i] / 32768.0;
    return buffer;
  };

  const initAudioEngine = async () => {
    if (!audioContextRef.current) {
      const AudioCtx = (window as any).AudioContext || (window as any).webkitAudioContext;
      audioContextRef.current = new AudioCtx({ sampleRate: 44100 });
      audioDestinationRef.current = audioContextRef.current.createMediaStreamDestination();
    }
    if (audioContextRef.current.state === 'suspended') await audioContextRef.current.resume();

    if (!bgmBufferRef.current) {
      const bgmUrl = storyboard.customBgmUrl || BGM_URLS[storyboard.bgm_style as keyof typeof BGM_URLS] || BGM_URLS.epic;
      const resp = await fetch(bgmUrl);
      const arrayBuffer = await resp.arrayBuffer();
      bgmBufferRef.current = await audioContextRef.current.decodeAudioData(arrayBuffer);
    }
  };

  const playNarration = (buffer: any) => {
    if (!audioContextRef.current || !audioDestinationRef.current) return;
    const source = audioContextRef.current.createBufferSource();
    source.buffer = buffer;
    source.connect(audioContextRef.current.destination);
    source.connect(audioDestinationRef.current);
    source.start();
    return source;
  };

  const playBGM = (totalDuration: number) => {
    if (!audioContextRef.current || !bgmBufferRef.current || !audioDestinationRef.current) return;
    const ctx = audioContextRef.current;
    const source = ctx.createBufferSource();
    source.buffer = bgmBufferRef.current;
    source.loop = true;
    const gain = ctx.createGain();
    const volume = 0.12;
    gain.gain.setValueAtTime(volume, ctx.currentTime);
    if (totalDuration > 2) {
      gain.gain.setValueAtTime(volume, ctx.currentTime + totalDuration - 2);
      gain.gain.linearRampToValueAtTime(0, ctx.currentTime + totalDuration);
    }
    source.connect(gain);
    gain.connect(ctx.destination);
    gain.connect(audioDestinationRef.current);
    source.start();
    return source;
  };

  const startFullProduction = async () => {
    if (!ffmpegReady || isExporting) return;
    setIsExporting(true);
    setExportStep("リソース読み込み中...");
    
    try {
      await initAudioEngine();
      // Cast to any to bypass potential environment-specific type missing properties like width/height
      const canvas = canvasRef.current as any;
      if (!canvas) return;
      
      canvas.width = 1080;
      canvas.height = 1920;

      const videoStream = (canvas as any).captureStream(30);
      const audioStream = audioDestinationRef.current!.stream;
      const combinedStream = new (window as any).MediaStream([
        ...videoStream.getVideoTracks(),
        ...audioStream.getAudioTracks()
      ]);

      const recorder = new (window as any).MediaRecorder(combinedStream, { mimeType: 'video/webm;codecs=vp9,opus' });
      const chunks: Blob[] = [];
      recorder.ondataavailable = (e: any) => { if (e.data.size > 0) chunks.push(e.data); };
      
      recorder.onstop = async () => {
        setExportStep("高画質MP4へ変換中...");
        const webmBlob = new Blob(chunks, { type: 'video/webm' });
        const ffmpeg = ffmpegRef.current;
        await ffmpeg.writeFile('input.webm', await fetchFile(webmBlob));
        await ffmpeg.exec(['-i', 'input.webm', '-c:v', 'libx264', '-preset', 'ultrafast', '-crf', '22', '-pix_fmt', 'yuv420p', '-c:a', 'aac', '-b:a', '128k', 'output.mp4']);
        const data = await ffmpeg.readFile('output.mp4');
        const mp4Blob = new Blob([data], { type: 'video/mp4' });
        setFinalVideoBlob(mp4Blob);
        const url = URL.createObjectURL(mp4Blob);
        // Access document via window to ensure it's found in environment
        const a = (window as any).document.createElement('a');
        a.href = url;
        a.download = `${storyboard.subject}_final.mp4`;
        a.click();
        setIsExporting(false);
        setExportStep("");
        setUploadStatus("制作完了！");
      };

      const totalEstimatedDuration = 3.5 + storyboard.scenes.reduce((acc, s) => acc + (s.duration || 5) + 0.8, 0);
      recorder.start();
      setIsPlaying(true);
      const bgmSource = playBGM(totalEstimatedDuration);
      
      setExportStep("レンダリング・録画中...");
      setCurrentSceneIndex(-1); 
      renderLoop();

      await new Promise(r => setTimeout(r, 3500)); 

      for (let i = 0; i < storyboard.scenes.length; i++) {
        setCurrentSceneIndex(i);
        startTimeRef.current = performance.now();
        const scene = storyboard.scenes[i];
        const audioBuffer = decodePCM(scene.audioUrl!, audioContextRef.current!);
        const narration = playNarration(audioBuffer);
        
        const media = mediaRefs.current[i];
        if (media && (media as any).tagName === 'VIDEO') {
          (media as any).currentTime = 0;
          (media as any).play().catch(() => {});
        }

        await new Promise(resolve => {
          narration!.onended = () => setTimeout(resolve, 800);
        });
      }

      setIsPlaying(false);
      recorder.stop();
      bgmSource?.stop();
    } catch (e: any) {
      console.error(e);
      setIsExporting(false);
      setExportStep("");
      setUploadStatus(`エラー: ${e.message}`);
    }
  };

  const renderLoop = () => {
    // Cast to any to bypass potential environment-specific type missing properties like getContext/width/height
    const canvas = canvasRef.current as any;
    if (!canvas || !isPlaying) return;
    const ctx = canvas.getContext('2d', { alpha: false });
    if (!ctx) return;

    ctx.imageSmoothingEnabled = true;
    ctx.imageSmoothingQuality = 'high';
    ctx.fillStyle = '#000000';
    ctx.fillRect(0, 0, canvas.width, canvas.height);

    if (currentSceneIndex === -1) {
      ctx.save();
      ctx.textAlign = 'center';
      ctx.textBaseline = 'middle';
      ctx.fillStyle = '#f59e0b';
      ctx.font = 'bold 120px "Noto Serif JP"';
      ctx.shadowColor = 'rgba(0,0,0,0.8)';
      ctx.shadowBlur = 30;
      ctx.fillText(storyboard.subject, canvas.width / 2, canvas.height / 2 - 100);
      ctx.fillStyle = 'white';
      ctx.font = 'bold 80px "Noto Serif JP"';
      ctx.fillText("の実は...", canvas.width / 2, canvas.height / 2 + 100);
      ctx.restore();
    } else if (currentSceneIndex >= 0) {
      const media = mediaRefs.current[currentSceneIndex];
      const scene = storyboard.scenes[currentSceneIndex];
      if (media) {
        const vR = ((media as any).tagName === 'VIDEO' ? (media as any).videoWidth : (media as any).naturalWidth) || 1080;
        const vH = ((media as any).tagName === 'VIDEO' ? (media as any).videoHeight : (media as any).naturalHeight) || 1920;
        const ratio = Math.max(canvas.width / vR, canvas.height / vH);
        
        // Ken Burns effect for static images or even videos
        const elapsed = (performance.now() - startTimeRef.current) / 1000;
        const duration = scene.duration || 5;
        const progress = Math.min(elapsed / duration, 1);
        const scale = 1.0 + (progress * 0.15); // Slight zoom in 1.0 -> 1.15
        
        const nw = vR * ratio * scale;
        const nh = vH * ratio * scale;
        
        ctx.save();
        ctx.translate(canvas.width / 2, canvas.height / 2);
        ctx.drawImage(media, -nw / 2, -nh / 2, nw, nh);
        ctx.restore();

        ctx.save();
        ctx.textAlign = 'center';
        ctx.font = 'bold 70px "Noto Serif JP"';
        const lines = scene.telop.length > 15 ? [scene.telop.slice(0, 15), scene.telop.slice(15)] : [scene.telop];
        lines.forEach((line, i) => {
          const textWidth = ctx.measureText(line).width;
          ctx.fillStyle = scene.telop_style === TelopStyle.HIGHLIGHT ? 'rgba(180, 0, 0, 0.9)' : 'rgba(0, 0, 0, 0.8)';
          ctx.fillRect((canvas.width - textWidth - 60) / 2, canvas.height * 0.75 + (i * 110), textWidth + 60, 100);
          ctx.fillStyle = 'white';
          ctx.fillText(line, canvas.width / 2, canvas.height * 0.75 + 75 + (i * 110));
        });
        ctx.restore();
      }
    }
    animationFrameRef.current = requestAnimationFrame(renderLoop);
  };

  const handleYouTubeUpload = async () => {
    const savedConfig = (window as any).localStorage.getItem('historian_yt_config');
    if (!savedConfig) {
      setUploadStatus("YouTube Client ID を登録してください。");
      return;
    }
    const { clientId } = JSON.parse(savedConfig) as YouTubeConfig;
    if (!clientId) return;

    if (!finalVideoBlob) return;
    setIsUploading(true);
    setUploadStatus("Google認証を実行中...");

    try {
      const client = (window as any).google.accounts.oauth2.initTokenClient({
        client_id: clientId,
        scope: YOUTUBE_SCOPES,
        callback: async (tokenResp: any) => {
          if (tokenResp.error) {
            setUploadStatus("認証エラーです。");
            setIsUploading(false);
            return;
          }
          const accessToken = tokenResp.access_token;
          setUploadStatus("アップロード中...");
          const metadata = {
            snippet: { title: ytMeta.title, description: ytMeta.description, tags: ytMeta.tags.split(',').map(s => s.trim()), categoryId: '22' },
            status: { privacyStatus: ytMeta.privacyStatus }
          };
          const initResp = await fetch('https://www.googleapis.com/upload/youtube/v3/videos?uploadType=resumable&part=snippet,status', {
            method: 'POST',
            headers: { 'Authorization': `Bearer ${accessToken}`, 'Content-Type': 'application/json; charset=UTF-8', 'X-Upload-Content-Length': finalVideoBlob.size.toString(), 'X-Upload-Content-Type': 'video/mp4' },
            body: JSON.stringify(metadata)
          });
          const uploadUrl = initResp.headers.get('Location');
          if (!uploadUrl) throw new Error("Permission denied");
          const uploadResp = await fetch(uploadUrl, { method: 'PUT', headers: { 'Content-Type': 'video/mp4' }, body: finalVideoBlob });
          if (uploadResp.ok) setUploadStatus("YouTubeアップロード成功！");
          else setUploadStatus(`失敗: ${uploadResp.status}`);
          setIsUploading(false);
        }
      });
      client.requestAccessToken();
    } catch (err: any) {
      setIsUploading(false);
      setUploadStatus(`エラー: ${err.message}`);
    }
  };

  return (
    <div className="fixed inset-0 z-[100] bg-black/95 flex items-center justify-center p-4 backdrop-blur-xl overflow-y-auto">
      <canvas ref={canvasRef} className="hidden" />
      <div className="w-full max-w-5xl grid grid-cols-1 lg:grid-cols-2 gap-12 items-center">
        <div className="relative aspect-[9/16] w-full max-w-[320px] mx-auto bg-black rounded-[2.5rem] overflow-hidden shadow-[0_0_50px_rgba(245,158,11,0.3)] border border-white/10">
          <div className="absolute inset-0">
            {currentSceneIndex === -1 ? (
              <div className="w-full h-full flex flex-col items-center justify-center bg-black">
                <h4 className="text-amber-500 font-bold text-4xl">{storyboard.subject}</h4>
                <p className="text-white text-xl mt-4">の実は...</p>
              </div>
            ) : currentSceneIndex >= 0 ? (
              storyboard.scenes.map((scene, idx) => (
                <div key={idx} className={`absolute inset-0 transition-opacity duration-500 ${idx === currentSceneIndex ? 'opacity-100' : 'opacity-0'}`}>
                  {scene.videoUrl && !scene.videoUrl.includes('data:image') ? (
                    <video ref={(el) => { if (el) mediaRefs.current[idx] = el; }} src={scene.videoUrl} className="w-full h-full object-cover" muted playsInline />
                  ) : (
                    <img ref={(el) => { if (el) mediaRefs.current[idx] = el; }} src={scene.imageUrl} className="w-full h-full object-cover" />
                  )}
                </div>
              ))
            ) : (
              <div className="w-full h-full flex items-center justify-center text-gray-500 uppercase text-xs tracking-widest font-mono">Standby</div>
            )}
          </div>
          {isExporting && (
             <div className="absolute inset-0 bg-black/60 flex flex-col items-center justify-center gap-4">
                <div className="w-12 h-12 border-4 border-amber-500 border-t-transparent animate-spin rounded-full"></div>
                <span className="text-white text-[10px] uppercase font-black tracking-widest text-center px-4">{exportStep}</span>
             </div>
          )}
        </div>

        <div className="space-y-8 animate-in slide-in-from-right duration-500">
          <div>
            <span className="text-amber-500 text-[10px] font-black uppercase tracking-widest mb-2 block">Movie Production Mode</span>
            <h3 className="text-4xl font-serif-jp text-white mb-4 leading-tight">{storyboard.title}</h3>
          </div>

          {!showUploadForm ? (
            <div className="grid gap-4">
              <button onClick={startFullProduction} disabled={isExporting || !ffmpegReady} className="bg-white text-black font-black py-6 rounded-full text-center hover:bg-amber-500 transition-all flex items-center justify-center gap-3 disabled:opacity-30">
                <svg className="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M4 16v1a3 3 0 003 3h10a3 3 0 003-3v-1m-4-4l-4 4m0 0l-4-4m4 4V4"/></svg>
                {isExporting ? "制作中..." : "制作してMP4を保存"}
              </button>
              <button onClick={() => setShowUploadForm(true)} className="bg-red-600 text-white font-black py-6 rounded-full text-center hover:bg-red-500 transition-all flex items-center justify-center gap-3">
                YouTubeに投稿する
              </button>
              <button onClick={onClose} className="text-white/30 text-[10px] font-black uppercase tracking-widest mt-4 hover:text-white transition-all text-center">Studioを終了</button>
            </div>
          ) : (
            <div className="bg-white/5 p-8 rounded-3xl border border-white/10 space-y-6">
              <h4 className="text-2xl font-serif-jp text-amber-500">Post to YouTube</h4>
              <div className="space-y-4">
                <input value={ytMeta.title} onChange={e => setYtMeta({...ytMeta, title: (e.target as any).value})} className="w-full bg-black/50 border border-white/10 p-4 rounded-xl text-white font-serif-jp" placeholder="タイトル" />
                <textarea rows={3} value={ytMeta.description} onChange={e => setYtMeta({...ytMeta, description: (e.target as any).value})} className="w-full bg-black/50 border border-white/10 p-4 rounded-xl text-white font-serif-jp text-xs" placeholder="説明欄" />
                <div className="grid grid-cols-2 gap-4">
                  <select value={ytMeta.privacyStatus} onChange={e => setYtMeta({...ytMeta, privacyStatus: (e.target as any).value})} className="bg-black border border-white/10 p-4 rounded-xl text-white outline-none text-sm">
                    <option value="private">非公開</option>
                    <option value="unlisted">限定公開</option>
                    <option value="public">一般公開</option>
                  </select>
                  <button onClick={handleYouTubeUpload} disabled={isUploading || !finalVideoBlob} className="bg-red-600 text-white font-black rounded-xl hover:bg-red-500 disabled:opacity-20 uppercase tracking-widest text-[10px]">
                    {isUploading ? "送信中..." : "アップロード"}
                  </button>
                </div>
                {uploadStatus && <p className="text-[11px] text-amber-500 text-center font-bold">{uploadStatus}</p>}
                <button onClick={() => setShowUploadForm(false)} className="text-gray-500 text-[10px] uppercase font-black block mx-auto hover:text-white">戻る</button>
              </div>
            </div>
          )}
        </div>
      </div>
    </div>
  );
};

export default VideoPreview;
